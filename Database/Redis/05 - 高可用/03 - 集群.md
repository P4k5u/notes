### 简介
Redis 3.0 版本起，推出了一种新的运行模式 Redis Cluster
Redis Cluster 采用无中心结构，具备多个节点之间自动进行数据分片的能力，支持节点动态添加与移除，可以在部分节点不可用时进行自动故障转移，确保系统高可用的一种集群化运行模式

### 集群数据结构

#### Cluster State（集群状态）
Redis Cluster 是 Redis 的一种运行模式，一切都要归属于 Redis 内最核心的数据结构 redisServer：
```lua
struct redisServer {
    /* Cluster */
    // 是否以集群模式运行
    int cluster_enabled;      /* Is cluster enabled? */
    
    // 集群节点通信超时参数
    mstime_t cluster_node_timeout; /* Cluster node timeout. */
    
    // 自动生成的配置文件（nodes.conf），用户不能修改，存储了集群状态
    char *cluster_configfile; /* Cluster auto-generated config file name. */
    
    // 集群状态，从当前redis实例视角来看当前集群的状态
    struct clusterState *cluster;  /* State of the cluster */
}
```
集群模式下每个 `redisServer` 通过 `clusterState` 来描述在它看来整个集群中所有节点的状态，`clusterState` 不仅包含自身节点的状态（myself）还包含集群内其他节点的状态（nodes）

clusterState 的几个基础字段：
- currentEpoch：集群当前纪元，其实就是集群版本，重新分片、故障转移等会改变当前集群版本
- myself：数据类型为 clusterNode，存储当前节点的状态
- nodes：字典类型，以 k-v 结构存储集群内所有的节点信息，k 为节点名称，v 的数据类型为 clusterNode
- slots：哈希槽与节点的映射关系，clusterNode 数组，以哈希槽编号为索引，指向负责节点

#### Cluster Node（节点属性）
Redis Cluster 通过数据结构 clusterNode 来描述一个集群节点信息与状态。
- 当 Redis 以集群模式启动后，就会初始化一个 clusterNode 对象，来维护自身状态
- 当节点通过握手或者心跳过程发现其他节点后，也会创建一个 clusterNode 来记录其他节点信息

`clusterNode`维护的信息有些是比较稳定或者是静态的，比如节点ID、ip和端口；也有一些会随着集群状态发生改变，比如节点负责的哈希槽范围、节点状态等

clusterNode 几个关键字段：
- name：每个节点都有一个唯一的ID，是识别节点的唯一依据
- flags：每个节点为了描述自身或其他节点的状态，以节点状态驱动系统流程，它虽然为int类型，但是其实只使用了低10位，每一位对应一个状态
- configEpoch：这里`configEpoch`描述的是节点的纪元，它与集群的当前纪元`currentEpoch`可能不同
- slots：节点负责的哈希槽，以bitmap方式存储了节点或者其主节点负责的哈希槽
- slaves：从节点数量
- slaveof：存储主节点
- link：当前节点与其他节点的网络连接
#### Cluster Bus（集群总线）
集群总线是Redis Cluster内部用于集群治理的专用链路，它由节点与节点之间一条条TCP链接构成。集群内的每个节点都会主动与其他所有节点建立链接，所以每个节点也会被其他所有节点连接。
其数据结构为`clusterLink`，封装了远程节点实例，以及与其的网络链接、接收和发送数据包的信息，基于它两个节点之间就可以保持实时通信了
### 通信协议

### 集群建立过程

集群创建的主要过程总结如下：
- 根据输入参数，redis-ci依次创建集群管理节点，并与每个节点建立网络链接，获取节点及已有集群信息
- 依次检查输入的节点，如是否为集群已有节点、节点是否为空
- 主从节点分配、哈希槽分配，判断节点是否满足集群创建的条件：至少三个主节点
- 输出哈希槽分片及主从节点分配，并在得到用户许可后执行节点配置
	- 针对主节点：通过`CLUSTER ADDSLOTS`命令，添加主节点负责的哈希槽范围
	- 针对从节点：通过`CLUSTER REPLICATE`命令，创建主从复制关系
	- 针对所有节点：通过`cluster set-config-epoch`命令，使其配置纪元（`config epoch`）加1
- redis-cli通过`cluster meet`命令触发节点握手过程，节点之间通过集群总线（`Cluster Bus`）传递`MEET`、`PING`、`PONG`等信息，逐步建立起集群关系
- 通过7000端口的节点检查集群节点及哈希槽分配情况
- 当集群建立以后，节点之间就会通过集群总线，使用二进制协议Gossip不断进行“闲聊”，以此完成节点发现、健康检查、故障检测、故障转移、配置更新、从节点迁移等工作

#### 核心步骤
##### 主从分配及数据分片
- 计算主节点数量
 redis-cli 计算主节点的数量，然后把所有节点按照一主N从进行分组。假设输入节点的数量为n，要求每个主节点的副本数为r，则理论上可以分为：m = n/(r+1) 其中，m为右边计算结果向下取整。按照集群模式的要求，至少需要3个主节点。如果m<3，则提示创建失败
- 分配主从节点
 优先考虑把主节点分配在不同的主机上，选择m个主节点，然后按照从节点数量r为主节点分配从节点。按照指定的从节点数量r分配完成后，如果还有剩余的节点，则再次执行从节点分配
- 数据分片
 默认会把 16384 个哈希槽分给主节点
##### 配置下发
从分配及数据分片完成后，redis-cli已经在本地为节点保存了主从配置及数据分片配置信息，得到管理员的许可后，会遍历节点列表把配置下发至对应的节点
##### 升级纪元
经过以上配置，各个节点已经不是刚刚启动时的状态，为了表明这种变化，redis-cli把各个节点的配置纪元升级，该命令为`cluster set-config-epoch`
##### 节点握手
到这里，每个单独的节点已经配置完成，接下来redis-cli会向节点发起握手命令，从零开始把节点逐个加入集群

握手过程通过集群总线完成

节点启动后监听集群总线端口，会接受一切外来的网络链接并接收其发送的消息，但是如果发现消息来源节点不是集群已知节点，其发送的所有消息将被丢弃。集群已有节点接受新节点加入集群只有两种方式：
- MEET请求：新节点以MEET消息发送请求，说明是由管理员发起的扩容命令，通过握手过程加入集群
- 自动发现：如果一个节点被集群中某个节点认可其是集群的有效节点，然后通过节点间的心跳告知其他节点，其他节点也会认为其是集群的有效节点。比如，已知集群中由A、B、C三个节点，通过MEET请求A认可了D，通过一段时间的心跳，B、C也会接受D作为集群的节点

这样子的话，只需要从第二个节点开始，依次与第一个节点握手，剩下的就交给自动发现即可把所有节点加入集群
### 数据分片机制

#### 哈希槽（Hash Slot）
Redis Cluster采用了类似于一致性哈希算法的哈希槽（hash slot）机制、由多个主节点共同分担所有key的管理工作

Redis Cluster使用CRC16算法把key空间分布在16384个哈希槽内，哈希槽是按照序号从0～16383标号的，每组主从节点只负责一部分哈希槽管理操作；而且通过集群状态维护哈希槽与节点之间的映射关系：
- Master-0 负责 Slots：0 ~ 5460
- Master-1 负责 Slots：5461 ~ 10922
- Master-2 负责 Slots：10923 ~ 16383

通过Redis Cluster对某个key执行操作时，接收请求的节点会首先对key执行计算，得到该key对应的哈希槽，然后再从哈希槽与节点的映射关系中找到负责该哈希槽的节点。
- 如果是节点自身，则直接进行处理
- 如果是其他节点，则通过重定向告知客户端连接至正确的节点进行处理

#### 哈希标签（Hash Tags）
Hash tags 用来将多个相关的 key 分配到相同的 Hash slots 中，就可以实现 multi-key 操作

哈希标签通过匹配 key 中 “{”、“}” 之间的字符串提取真正用于计算哈希槽的 key

客户端输入的key可能存在多个“{”或“}”，此时Redis Cluster将会如下规则处理：
- key中存在“{”字符，并且“{”的右侧存在“}”
- “{”与“}”之间存在一个或多个字符

一些例子：
- `{user1000}.following` 和`{user1000}.followers`：最终采用`user1000`
- `foo{}{bar}`：最终采用`foo{}{bar}`
- `foo{{bar}}zap`：最终采用`{bar`
- `foo{bar}{zap}`：最终采用`bar`
#### 重新分片
Redis Cluster 支持在不停机情况下添加或移除节点（扩容/缩容）

哈希槽的分配其实是一个数组，数组索引序号对应哈希槽，数组值为负责哈希槽的节点。理论上，哈希槽的重新分配实质上是根据数组索引修改对应的节点对象，然后通过状态传播在集群所有节点达到最终一致。
如下图中，把负责哈希槽1001的节点从7000修改为7001![[Pasted image 20231125195607.png]]
当把哈希槽负责的节点从旧节点改为新节点时，需要考虑旧节点存量key的迁移问题，也就是要把旧节点哈希槽中的key全部转移至新的节点

重新分片过程中，客户端的请求并没有停止，Redis还需要正确响应客户端请求，使之不受影响

迁移哈希槽的过程如下图所示（每幅图上面为源节点，下面为目标节点）：![[Pasted image 20231125200744.png]]
这是把哈希槽1000，从7000节点迁移至7001节点的集群状态变化过程：
- 修改源节点和目标节点的迁移状态，对应第一幅图：
	- 通知目标节点，把 slot 改为 importing 状态
	- 通知源节点，把 slot 改为 migrating 状态
- 迁移源节点slot中的key到目标节点，对应第二、三幅图
	- 使用命令`CLUSTER GETKEYSINSLOT <slog> <pipeline>`从源节点查询slot中所有的keys
	- 使用`MIGRATE`程序把keys从源节点迁移至目标节点，逐个迁移key，每个key的迁移是原子操作，期间会锁定双方节点
- 通知所有节点，把负责slot的节点设置为最新节点，同时移除源节点、目标节点中的importing、migrating状态，对应第四幅图

#### 重定向
数据分片使得所有的key分散存储在不同的节点，而且随着重新分片或者故障转移，哈希槽与节点之间的映射关系会发生改变，那么需要一定的机制来进行处理
##### MOVED 重定向
由于数据分片机制，Redis集群中每个节点仅负责一部分哈希槽，也就是一部分key的存储及管理工作。
客户端发送命令请求时，是向任意一个节点发送，节点收到后，就会计算请求的key对应的 hash slots ：
- 槽命中：执行命令返回结果
- 槽未命中：返回一个 MOVED 错误
当客户端接收到 MOVED 错误后，就会解析出该key的节点ip和端口，然后重新执行命令

如果客户端与节点之间总是通过重定向的方式处理命令，那么性能肯定不如单机的 Redis。为此，Redis 提供了两种可选的方案：
- 执行请求前，计算 hash slots 之后，把可以执行命令的节点保存起来，由客户端来维护 key -> hash slots -> 节点 的映射关系
- 通过命令`CLUSTER NODES`查询集群节点状态，从中获取哈希槽与节点的映射关系，在客户端本地缓存起来。每次请求时，先计算key的哈希槽，再查询节点（例如：smart 客户端JedisCluster）
##### ASK 重定向
在重新分片时，源节点向目标节点迁移哈希槽的过程中，该哈希槽所存储的key有的在源节点，有的已经迁移至目标节点。此时客户端向源节点发起命令请求（尤其是多key的情况），MOVED重定向就无法正常的工作了![[Pasted image 20231126114517.png]]

当命令中包含多个相同哈希槽的key，比如 {test}1、{test}2，当集群处于重新分片时，请求的keys可能有些未迁移，有些已经迁移：
- 未迁移：keys存储在自己节点内，可以正常处理请求
- 已迁移：此时keys已经被完全或部分迁移至其他节点，所以执行时无法找到keys，无法正常处理请求
这时MOVED重定向已经不管用，所以 Redis Cluster 引入了 ASK 重定向

ASK 重定向执行流程如下：
- 所请求的key还在节点中：直接返回结果
- 完全迁移或部分迁移：以 ASK 重定向错误高速客户端需要请求的节点
	- 客户端收到ASK重定向错误信息后，设置新的请求节点，并向其发送ASKING命令
	- 节点收到ASKIING命令后，如果迁移完成，返回结果；迁移未完成，返回重试错误（TRYAGAIN）
	- 当迁移完成后，客户端将收到 MOVED 重定向错误，就试用 MOVED 重定向逻辑进行请求
##### MOVED 重定向与 ASK 重定向的区别
- MOVED 重定向：以哈希槽与节点的映射关系为基础的。如果客户端接收到此错误，可以直接更新本地的哈希槽与节点的映射关系缓存。这是一种相对稳定的状态
- ASK 重定向：告知客户端，它所请求的keys对应的哈希槽当前正在迁移至新的节点，客户端接收到此错误，将会临时（一次性）重定向，以询问（ASKING）的方式向新节点发起请求尝试。该错误不会影响接下来客户端对相同哈希槽的请求，除非它再次收到ASK重定向错误（下次还是会请求同一个节点）
### 集群容错机制