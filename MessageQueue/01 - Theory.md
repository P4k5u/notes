### 简介
消息队列已经逐渐成为企业IT系统内部通信的核心手段。它具有低耦合、可靠投递、广播、流量控制、最终一致性等一系列功能，成为异步RPC的主要手段之一。 
当今市面上有很多主流的消息中间件，如老牌的ActiveMQ、RabbitMQ，炙手可热的Kafka，阿里巴巴自主开发的Notify、MetaQ、RocketMQ等

从零开始分析设计一个消息队列时需要考虑到的问题，如RPC、高可用、顺序和重复消息、可靠投递、消费关系解析

当你需要使用消息队列时，首先需要考虑它的必要性。可以使用mq的场景有很多，最常用的几种，是做业务解耦/最终一致性/广播/错峰流控等。反之，如果需要强一致性，关注业务逻辑的处理结果，则RPC显得更为合适

### 使用场景
#### 解耦
接耦是消息队列要解决的最本质问题，所谓解耦，简单讲就是一个事务，只关心核心的流程，而需要依赖其他系统但不那么重要的事情，有通知即可，无需等待结果。
关心的是“通知”，而非“处理”。

比如，有一个产品中心，产品中心上游对接的是各个数据源；下游对接的是展示系统。当上游的数据发生变更的时候，如果不使用消息系统，势必要调用我们的接口来更新数据，就特别依赖产品中心接口的稳定性和处理能力。但其实，作为产品中心，对于数据源来说，产品中心更新成功也好、失败也罢，并不是他们的职责所在。他们只需要保证在信息变更的时候通知到我们就好了。 而我们的下游，可能有更新索引、刷新缓存等一系列需求。对于产品中心来说，这也不是我们的职责所在。说白了，如果他们定时来拉取数据，也能保证数据的更新，只是实时性没有那么强。但使用接口方式去更新他们的数据，显然对于产品中心来说太过于“重量级”了，只需要发布一个产品ID变更的通知，由下游系统来处理，可能更为合理
#### 最终一致性
最终一致性指的是两个系统的状态保持一致，要么都成功，要么都失败。当然有个时间限制，理论上越快越好，但实际上在各种异常的情况下，可能会有一定延迟达到最终一致状态，但最后两个系统的状态是一样的。

所有跨VM的一致性问题，从技术角度讲通用的解决方案：
1. 强一致性：分布式事务，但落地太难且成本太高
2. 最终一致性：主要是用“记录”和“补偿”的方式。在做所有的不确定的事情之前，先把事情记录下来，然后去做不确定的事情，结果可能是：成功、失败或是不确定，“不确定”（例如超时等）可以等价为失败。成功就可以把记录的东西清理掉了，对于失败和不确定，可以依靠定时任务等方式把所有失败的事情重新搞一遍，直到成功为止
最终一致性不是消息队列的必备特性，但确实可以依靠消息队列来做最终一致性的事情。另外，所有不保证100%不丢消息的消息队列，理论上无法实现最终一致性。好吧，应该说理论上的100%，排除系统严重故障和bug。 像Kafka一类的设计，在设计层面上就有丢消息的可能（比如定时刷盘，如果掉电就会丢消息）。哪怕只丢千分之一的消息，业务也必须用其他的手段来保证结果正确

#### 广播
消息队列的基本功能之一是进行广播。如果没有消息队列，每当一个新的业务方接入，我们都要联调一次新接口。有了消息队列，我们只需要关心消息是否送达了队列，至于谁希望订阅，是下游的事情，无疑极大地减少了开发和联调的工作量
#### 错峰与流控
上下游对于事情的处理能力是不同的，利用中间系统转储两个系统的通信内容，并在下游系统有能力处理这些消息的时候，再处理这些消息，是一套相对较通用的方式
### 消息队列的设计
消息的系统模型![[Pasted image 20231213163510.png]]
基于消息的系统模型，不一定需要broker(消息队列服务端)。市面上的的Akka（actor模型）、ZeroMQ等，其实都是基于消息的系统设计范式，但是没有broker。 我们之所以要设计一个消息队列，并且配备broker，无外乎要做两件事情：
1. 消息的转储：在更合适的时间点投递，或者通过一系列手段辅助消息最终能送达消费机
2. 规范一种范式和通用的模式：最简单的消息队列可以做成一个消息转发器，把一次RPC做成两次RPC。发送者把消息投递到服务端（以下简称broker），服务端再将消息转发一手到接收端
一般来讲，设计消息队列的整体思路：
-  build 一个整体的数据流,例如 producer 发送给 broker ,broker 发送给 consumer, consumer 回复消费确认，broker 删除/备份消息等。
- 利用 RPC 将数据流串起来。然后考虑 RPC 的高可用性，尽量做到无状态，方便水平扩展。 
- 考虑如何承载消息堆积，然后在合适的时机投递消息，而处理堆积的最佳方式，就是存储。
- 为了实现广播功能，需要维护消费关系，可以利用 zk/config server 等保存消费关系
### 基本功能

#### RPC通信协议

#### 高可用
这里的高可用，是基于RPC和存储的高可用来做的，RPC 的高可用由 RPC 框架决定，MQ 只用保证 broker 接收消息和确认消息的接口是幂等的，且 consumer 处理消息是幂等的，就可以把高可用转交给 RPC 框架来处理

保证幂等的话就采用 共享存储 的方式，broker 多机器共享一个 DB ，则处理消息自然是幂等的

#### 服务端承载消息堆积的能力
消息到达服务端如果不经过任何处理就到接收者了，broker 就失去了它的意义。为了满足我们错峰/流控/最终可达等一系列需求，把消息存储下来，然后选择时机投递就显得是顺理成章的了

存储消息有很多种方式，比如存储在内存里，存储在分布式KV里，存储在磁盘里，存储在数据库里
但主要就是 持久化 和 非持久化 两种：
- 持久化：更大程度保证消息的可靠性，承载更大的消息堆积
- 非持久化：性能更高，消息不落地暂存内存了，尝试几次 failover ，最终投递出去
#### 存储子系统的选择
如果需要数据落地的情况下各种存储子系统的选择。理论上，从速度来看，文件系统>分布式KV（持久化）>分布式文件系统>数据库，而可靠性却截然相反

#### 消费关系解析
解析发送接收关系，进行正确的消息投递。
市面上的消息队列定义了一堆让人晕头转向的名词，如JMS 规范中的Topic/Queue，Kafka里面的Topic/Partition/ConsumerGroup，RabbitMQ里面的Exchange等等

无外就是单薄与广播的区别，单播，就是点到点；广播，就是一点对多点。对于互联网的大厂来说，组间广播、组内单播是最常见的情形。

组内单播：消息需要通知到多个业务集群，而一个业务集群内有很多台机器，只要一台机器消费这个消息就可以了
组间广播：比如，本地缓存的更新等

一般比较通用的设计是支持组间广播，不同的组注册不同的订阅。组内的不同机器，如果注册一个相同的ID，则单播；如果注册不同的ID(如IP地址+端口)，则广播

至于广播关系的维护，一般由于消息队列本身都是集群，所以都维护在公共存储上，如config server、zookeeper等。维护广播关系所要做的事情基本是一致的：
1. 发送关系的维护
2. 发送关系变更时的通知

### 高级特性

#### 可靠投递（最终一致性）
完全不丢消息，究竟可不可能？答案是，完全可能，前提是消息可能会重复，并且，在异常情况下，要接受消息的延迟。 方案说简单也简单，就是每当要发生不可靠的事情（RPC等）之前，先将消息落地，然后发送。当失败或者不知道成功失败（比如超时）时，消息状态是待发送，定时任务不停轮询所有待发送消息，最终一定可以送达
具体来说：
1. producer 往 broker 发送消息之前，需要做一次落地
2. 请求到 server 后，server 确保数据落地后再告诉客户端发送成功
3. 支持广播的消息队列需要对每个待发送的endpoint，持久化一个发送状态，直到所有endpoint 状态都 OK 才可删除消息
对于各种不确定（超时、down机、消息没有送达、送达后数据没落地、数据落地了回复没收到），其实对于发送方来说，都是一件事情，就是消息没有送达。 重推消息所面临的问题就是消息重复。重复和丢失就像两个噩梦，你必须要面对一个。好在消息重复还有处理的机会，消息丢失再想找回就难了
##### 消费确认
当broker把消息投递给消费者后，消费者可以立即响应我收到了这个消息。但收到了这个消息只是第一步，我能不能处理这个消息却不一定。或许因为消费能力的问题，系统的负荷已经不能处理这个消息；或者是刚才状态机里面提到的消息不是我想要接收的消息，主动要求重发。 把消息的送达和消息的处理分开，这样才真正的实现了消息队列的本质-解耦
所以，允许消费者主动进行消费确认是必要的。当然，对于没有特殊逻辑的消息，默认Auto Ack也是可以的，但一定要允许消费方主动ack。 

对于正确消费ack的，没什么特殊的。但是对于reject 和 error，需要特别说明：
- reject ：对于 reject，往往业务方是无法感知到的，系统的流量和健康状况的评估，以及处理能力的评估是一件非常复杂的事情。举个极端的例子，收到一个消息开始build索引，可能这个消息要处理半个小时，但消息量却是非常的小。所以reject这块建议做成滑动窗口/线程池类似的模型来控制， 消费能力不匹配的时候，直接拒绝，过一段时间重发，减少业务的负担。
- error：发送 error 是只有业务方自己知道的，就像上文提到的状态机等等。这时应该允许业务方主动ack error。

##### 重复消息和顺序消息
重复消息是不可能100%避免的，除非可以允许丢失，那么，顺序消息能否100%满足呢? 答案是可以，但条件更为苛刻：
1. 允许消息丢失
2. 从发送方到服务方到接受者都是单点单线程

所以绝对的顺序消息基本上是不能实现的，当然在METAQ/Kafka等pull模型的消息队列中，单线程生产/消费，排除消息丢失，也是一种顺序消息的解决方案

一般来讲，一个主流消息队列的设计范式里，应该是不丢消息的前提下，尽量减少重复消息，不保证消息的投递顺序。 谈到重复消息，主要是两个话题：
1. 如何鉴别消息重复，并幂等的处理重复消息
2. 一个消息队列如何尽量减少重复消息的投递
先来看看第一个话题，每一个消息应该有它的唯一身份。不管是业务方自定义的，还是根据IP/PID/时间戳生成的MessageId，如果有地方记录这个MessageId，消息到来是能够进行比对就 能完成重复的鉴定。数据库的唯一键/bloom filter/分布式KV中的key，都是不错的选择

由于消息不能被永久存储，所以理论上都存在消息从持久化存储移除的瞬间上游还在投递的可能（上游因种种原因投递失败，不停重试，都到了下游清理消息的时间）。这种事情都是异常情况下才会发生的，毕竟是小众情况。两分钟消息都还没送达，多送一次又能怎样呢？

因为种种原因重复消息或者错乱的消息还是来到了，而幂等的处理一般有两种通用的解决方案：
1. 版本号：如果每个消息自带一个版本号。上游发送的时候，标记消息1版本号是1，消息2版本号是2。如果再发送下线消息，则版本号标记为3。下游对于每次消息的处理，同时维护一个版本号。 每次只接受比当前版本号大的消息
2. 状态机：业务方只需要自己维护一个状态机，定义各种状态的流转关系。例如，”下线”状态只允许接收”上线”消息，“上线”状态只能接收“下线消息”，如果上线收到上线消息，或者下线收到下线消息，在消息不丢失和上游业务正确的前提下。要么是消息发重了，要么是顺序到达反了。这时消费者只需要把“我不能处理这个消息”告诉投递者，要求投递者过一段时间重发即可。而且重发一定要有次数限制，比如5次，避免死循环，就解决了

##### 中间件对重复消息的处理
我们保证不丢失消息的情况下尽量少重复消息，消费顺序不保证。那么重复消息下和乱序消息下业务的正确，应该是由消费方保证的，我们要做的是减少消息发送的重复。 我们无法定义业务方的业务版本号/状态机，如果API里强制需要指定版本号，则显得过于绑架客户了。况且，在消费方维护这么多状态，就涉及到一个消费方的消息落地/多机间的同步消费状态问题，复杂度指数级上升，而且只能解决部分问题。 减少重复消息的关键步骤：
1. broker 记录 MessageId，直到投递成功后清除，重复的 ID 到来不做处理，这样只要发送者在清除周期内能够感知到消息投递成功，就基本不会在 server 端产生重复消息。
2. 对于 server 投递到 consumer 的消息，由于不确定对端是在处理过程中还是消息发送丢失的情况下，有必要记录下投递的IP地址。决定重发之前询问这个IP，消息处理成功了吗？如果询问无果，再重发。

#### 事务
持久性是事务的一个特性，然而只满足持久性却不一定能满足事务的特性。满足事务的一致性特征，则必须要么都不进行，要么都能成功。 解决方案从大方向上有两种：
1. 两阶段提交，分布式事务
2. 本地事务，本地落地，补偿发送

分布式事务存在的最大问题是成本太高，两阶段提交协议，对于仲裁down机或者单点故障，几乎是一个无解的黑洞。对于交易密集型或者I/O密集型的应用，没有办法承受这么高的网络延迟，系统复杂性。 并且成熟的分布式事务一定构建与比较靠谱的商用DB和商用中间件上，成本也太高

本地事务解决分布式事务：以本地和业务在一个数据库实例中建表为例子，与扣钱的业务操作同一个事务里，将消息插入本地数据库。如果消息入库失败，则业务回滚；如果消息入库成功，事务提交。 然后发送消息（注意这里可以实时发送，不需要等定时任务检出，以提高消息实时性）。
本地事务做的，是业务落地和消息落地的事务，而不是业务落地和RPC成功的事务

另外事务的使用应该尽量低成本、透明化，可以依托于现有的成熟框架，如Spring的声明式事务做扩展。业务方只需要使用@Transactional标签即可
#### 性能相关

异步 / 同步
首先澄清一个概念，异步，同步和oneway是三件事。异步，归根结底你还是需要关心结果的，但可能不是当时的时间点关心，可以用轮询或者回调等方式处理结果；同步是需要当时关心 的结果的；而oneway是发出去就不管死活的方式

任何的RPC都是存在客户端异步与服务端异步的，而且是可以任意组合的。 对于客户端来说，同步与异步主要是拿到一个Result，还是Future(Listenable)的区别。实现方式可以是线程池，NIO或者其他事件机制。 服务端异步是需要RPC协议支持的。参考servlet 3.0规范，服务端可以吐一个future给客户端，并且在future done的时候通知客户端

客户端同步服务端异步：
```java
Future<Result> future = request(server);//server立刻返回future 
synchronized(future){ while(!future.isDone()){ future.wait();//server处理结束后会notify这个future，并修改isdone标志 
}
} 
return future.get();
```
客户端同步服务端同步：
```java
Result result = request(server);
```
客户端异步服务端同步(这里用线程池的方式）：
```java
Future<Result> future = executor.submit(new Callable(){public void call<Result>(){ result = request(server); }}) return future;
```
客户端异步服务端异步：
```java
Future<Result> future = request(server);//server立刻返回future 
return future
```

#### 批量
谈到批量就不得不提生产者消费者模型。但生产者消费者模型中最大的痛点是：消费者到底应该何时进行消费。消费动作都是事件驱动的。主要事件包括：
1. 攒够了一定数量
2. 到达了一定时间
3. 队列里有新的数据到来

只要队列有数据，就把队列中的所有数据刷出，否则将自己挂起，等待新数据的到来。 在第一次把队列数据往外刷的过程中，又积攒了一部分数据，第二次又可以形成一个批量。伪代码如下:
```java
    Executor executor = Executors.newFixedThreadPool(4);  
    final BlockingQueue<Message> queue = new ArrayBlockingQueue<>();  
    private Runnable task = new Runnable({//这里由于共享队列，Runnable可以复用，故做成全局的  
  
    public void run() {  
        List<Message> messages = new ArrayList<>(20);  
        queue.drainTo(messages，20);  
        doSend(messages);//阻塞，在这个过程中会有新的消息到来，如果4个线程都占满，队列就有机会囤新的消息  
    }  
});  
  
public void send(Message message) {  
    queue.offer(message);  
    executor.submit(task)  
}
```
这种方式是消息延迟和批量的一个比较好的平衡，但优先响应低延迟。延迟的最高程度由上一次发送的等待时间决定：
```java
    Executor executor = Executors.newFixedThreadPool(4);  
    final BlockingQueue<Message> queue = new ArrayBlockingQueue<>();  
    volatile long last = System.currentMills();  
Executors.newSingleThreadScheduledExecutor().  
  
    submit(new Runnable() {  
        flush();  
    }，500，500，TimeUnits.MILLS);  
    private Runnable task = new Runnable({//这里由于共享队列，Runnable可以复用，顾做成全局的。  
  
    public void run() {  
        List<Message> messages = new ArrayList<>(20);  
        queue.drainTo(messages，20);  
        doSend(messages);//阻塞，在这个过程中会有新的消息到来，如果4个线程都占满，队列就有机会屯新的消息。  
    }  
});  
  
public void send(Message message) {  
    last = System.currentMills();  
    queue.offer(message);  
    flush();  
}  
  
private void flush() {  
    if (queue.size > 200 || System.currentMills() - last > 200) {  
        executor.submit(task)  
    }  
}
```
相反对于可以用适量的延迟来换取高性能的场景来说，用定时/定量二选一的方式可能会更为理想，既到达一定数量才发送，但如果数量一直达不到，也不能干等，有一个时间上限。 具体说来，在上文的submit之前，多判断一个时间和数量，并且Runnable内部维护一个定时器，避免没有新任务到来时旧的任务永远没有机会触发发送条件
### push / pull 
上文提到的消息队列，大多是针对push模型的设计。现在市面上有很多经典的也比较成熟的pull模型的消息队列，如Kafka、MetaQ等。这跟JMS中传统的push方式有很大的区别，可谓另辟蹊径。 我们简要分析下push和pull模型各自存在的利弊。

#### 慢消费
慢消费无疑是push模型最大的致命伤，当成流水线来看，如果消费者的速度比发送者的速度慢很多，势必造成消息在broker的堆积。假设这些消息都是有用的无法丢弃的，消息就要一直在broker端保存。当然这还不是最致命的，最致命的是broker给consumer推送一堆consumer无法处理的消息，consumer不是reject就是error，然后来回踢皮球。

反观pull模式，consumer可以按需消费，broker堆积消息也会相对简单，无需记录每一个要发送消息的状态，只需要维护所有消息的队列和偏移量就可以了。所以对于建立索引等慢消费，消息量有限且到来的速度不均匀的情况，pull模式比较合适
#### 消息延迟与忙等
这是pull模式最大的短板。由于主动权在消费方，消费方无法准确地决定何时去拉取最新的消息。如果没有pull取到则需要等待一段时间重新pull。 但等待多久就很难判定了。你可能会说，我可以有xx动态pull取时间调整算法，但问题的本质在于，有没有消息到来这件事情决定权不在消费方。也许1分钟内连续来了1000条消息，然后半个小时没有新消息产生， 可能你的算法算出下次最有可能到来的时间点是31分钟之后，或者60分钟之后，结果下条消息10分钟后到了，是不是很让人沮丧？

当然也不是说延迟就没有解决方案了，业界较成熟的做法是从短时间开始（不会对broker有太大负担），然后指数级增长等待。比如开始等5ms，然后10ms，然后20ms，然后40ms……直到有消息到来，然后再回到5ms。 即使这样，依然存在延迟问题：假设40ms到80ms之间的50ms消息到来，消息就延迟了30ms。

在阿里的RocketMq里，有一种优化的做法-长轮询，来平衡推拉模型各自的缺点。基本思路是:消费者如果尝试拉取失败，不是直接return,而是把连接挂在那里wait,服务端如果有新的消息到来，把连接notify起来，这也是不错的思路。但海量的长连接block对系统的开销还是不容小觑的，还是要合理的评估时间间隔，给wait加一个时间上限比较好
#### 顺序消息
如果push模式的消息队列，支持分区，单分区只支持一个消费者消费，并且消费者只有确认一个消息消费后才能push送另外一个消息，还要发送者保证全局顺序唯一，听起来也能做顺序消息，但成本太高了，尤其是必须每个消息消费确认后才能发下一条消息，这对于本身堆积能力和慢消费就是瓶颈的push模式的消息队列，简直是一场灾难。 反观pull模式，如果想做到全局顺序消息，就相对容易很多：
1. producer对应partition，并且单线程。
2. consumer对应partition，消费确认（或批量确认），继续消费即可。

所以对于日志push送这种最好全局有序，但允许出现小误差的场景，pull模式非常合适