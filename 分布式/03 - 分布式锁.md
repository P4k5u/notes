### 简介
开发过程中，大致可以分为三种维度的锁：
- 线程锁：主要用来给方法、代码块加锁，保证同一时刻只有一个线程执行该方法或代码段，线程只在同一 JVM 中有效，因为线程锁的本质是依靠线程之间共享内存实现的，synchronized 共享对象头、Lock 共享 state
- 进程锁：为了控制同一系统中多个进程访问某个共享资源，因为进程具有独立性，各个进程无法访问其他进程的资源，一般使用 FileLock 
- 分布式锁：当多个进程不在同一个系统中，用分布式锁来控制多个进程对资源的访问
### 分布式锁的设计原则
Redis 官网上对于分布式锁提出的至少满足的三个要求：
- 互斥（只有一个客户端能获取）
- 无死锁
- 容错性（大部分 redis 节点创建了这把锁就行）
除此之外，分布式锁的设计中还可以考虑：
- 加锁解锁的同源性：A 加的锁，不能被 B 解锁
- 非阻塞获取锁：如果获取不到锁，不能无限等待
- 高性能：加锁解锁是高性能的

### 数据库实现
#### 创建锁表
直接创建一张锁表，然后通过操作该表中的数据来实现，当想要获得锁时，就可以在该表中增加一条记录，想要释放锁的时候就删除这条记录

#### 基于悲观锁
在 InnoDB 中，使用 `select ... for update` 的方式来实现悲观锁
需要注意的是，InnDB 默认行级锁，行级锁都是基于索引的，如果 SQL 语句中没有索引就会使用表锁来把整张表锁住

#### 基于乐观锁
可以使用版本号来实现，在数据初始化时指定一个版本号，每次对数据的更新操作都对版本号执行+1操作。并判断当前版本号是不是该数据的最新的版本号

### Redis 实现
基于 set NX 实现的分布式锁存在的问题：
- 如果setnx成功，还没来得及释放，服务挂了，那么这个key永远都不会被获取到
- setnx和expire是两个方法，不能保证原子性，如果在setnx之后，还没来得及expire，服务挂了，还是会出现锁不释放的问题
- 如果在过期时间内，事务还没有执行完，锁提前被自动释放，其他的线程还是可以拿到锁
- 集群环境下，对master节点申请了分布式锁，由于redis的主从同步是异步进行的，master在内存中写入了nx之后直接返回，客户端获取锁成功，此时master节点挂了，并且数据还没来得及同步，另一个节点被升级为master，这样其他的线程依然可以获取锁

#### set NX PX + 唯一 Id + Lua（单节点）
我们可以用 lua 来写一个 getkey 并比较的脚本，jedis/luttce/redisson对lua脚本都有很好的支持

setnx 的时候将 value 设为一个能够区分客户端表示的 ID 信息
```shell
# 设置一个 100 秒过期的锁
set lock_key client_unique_value nx ex 100
```
释放的时候先 get key 比较一下 value 是否与当前的id相同，是则释放，否则抛异常回滚，其实也是变相地解决了被其他线程释放锁的问题，可以用 lua 脚本来保障原子性
```lua
// 释放锁 比较 unique_value 是否相等，避免误释放
// KEYS[1] 和 ARGV[1] 都是调用脚本的时候传参进来的，前者代表锁的 key，后者代表客户端唯一 ID

if redis.call("get",KEY[1])== ARGV[1] then 
  return redis.call("del",KEYS[1])
else
  return 0
end
```

#### RedLock（集群）
如果是在 分布式集群 情况下，推荐用 RedLock 实现分布式锁

Redis的作者 antirez 的提出了red lock的概念，假设集群中所有的n个master节点完全独立，并且没有主从同步，此时对所有的节点都去setnx，并且设置一个 请求过期时间re 和 锁的过期时间le ，同时re必须小于 le，此时如果有n / 2 + 1个节点成功拿到锁，此次分布式锁就算申请成功

假设有两个服务A、B 都希望获取锁，有一个包含了 5 个 Redis master 的 Redis Cluster
执行过程如下：
1. 客户端获取当前时间戳，单位：毫秒
2. 服务 A 轮询每个 master 节点，尝试创建锁（锁的过期时间比较短，十几毫秒），RedLock 算法会尝试在大多数节点上分别创建锁，假如节点总数为 n ，那么大多数节点指的是 n/2+1 
3. 客户端计算成功建锁的时间，如果建锁时间小于超时时间，就可以判定锁创建成功。如果锁创建失败，则依次遍历 master 节点删除锁

在 Redis 主从复制过程中，服务 A 获取到锁之后，master 节点复制数据到 slave 节点时，发生崩溃，这就会导致重新选主之后的节点没有该锁的记录，导致锁丢失，用 RedLock 的话就可以避免这种情况的发生

#### Redisson
Redis 的客户端（Jedis、Redisson、Lettuce等）都是基于 Lua 脚本或 RedLock 来实现分布式锁的，只是对相关的方法进行了封装和优化

常用的是方案是使用 Redisson 来实现分布式锁

Redisson 的所有指令都通过 Lua 脚本执行，并且设置了 watchdog 来进行锁的超时续约的方式，且支持 RedLock 的实现方式

可以实现可重入、重试、超时续约等功能

##### 工作流程
- 线程获取锁成功，执行 Lua 脚本，保存数据到 redis 数据库
- 线程获取锁失败，订阅解锁消息，再尝试获取锁

简单代码使用：
```java
// 1.设置分布式锁
RLock lock = redisson.getLock("lock");
// 2.占用锁
lock.lock();
// 3.执行业务
...
// 4.释放锁
lock.unlock();
```
##### 可重入锁

##### WatchDog 机制
如果负责储存这个分布式锁的 Redisson 节点宕机以后，而且这个锁正好处于锁住的状态时，这个锁会出现锁死的状态。为了避免这种情况的发生，Redisson 内部提供了一个监控锁的`看门狗`，它的作用是在 Redisson 实例被关闭前，不断的延长锁的有效期

默认情况下，看门狗的检查锁的超时时间是 30 秒钟，也可以通过修改 Config.lockWatchdogTimeout 来设置
只要占锁成功，就会启动一个`定时任务`：每隔 10 秒重新给锁设置过期的时间，过期时间为 30 秒

当服务器宕机后，因为锁的有效期是 30 秒，所以会在 30 秒内自动解锁。（30 秒等于宕机之前的锁占用时间+后续锁占用的时间）

### Zookeeper 实现
可以利用顺序节点来实现
创建一个用于发号的节点 `/lock` 然后以它为父节点的前缀为 `/lock/seq-` 依次发号![[Pasted image 20240128171647.png]]
（1）创建一个目录 lock；  
（2）线程A想获取锁就在 lock目录下创建临时顺序节点；  
（3）获取lock目录下所有的子节点，然后获取比自己小的兄弟节点，如果不存在，则说明当前线程顺序号最小，获得锁；  
（4）线程B获取所有节点，判断自己不是最小节点，设置监听比自己次小的节点；  
（5）线程A处理完，删除自己的节点，线程B监听到变更事件，判断自己是不是最小的节点，如果是则获得锁

**优点**：具备高可用、可重入、阻塞锁特性，可解决失效死锁问题。

**缺点**：因为需要频繁的创建和删除节点，性能上不如Redis 方式

实现原理：
- **1、利用临时节点特性**  
    zookeeper的临时节点有两个特性，一是节点名称不能重复，二是会随着客户端退出而销毁，因此直接将key作为节点名称，能够成功创建的客户端则获取成功，失败的客户端监听成功的节点的删除事件  
    **缺点**：所有客户端监听同一个节点，但是同时只有一个节点的事件触发是有效的，造成资源的无效调度
- **2、利用顺序临时节点特性**  
    zookeeper的顺序临时节点拥有临时节点的特性，同时，在一个父节点下创建创建的子临时顺序节点，会根据节点创建的先后顺序，用一个32位的数字作为后缀，我们可以用key创建一个根节点，然后每次申请锁的时候在其下创建顺序节点，接着获取根节点下所有的顺序节点并排序，获取顺序最小的节点，如果该节点的名称与当前添加的名称相同，则表示能够获取锁，否则监听根节点下面的处于当前节点之前的节点的删除事件，如果监听生效，则回到上一步重新判断顺序，直到获取锁
### Consul 实现